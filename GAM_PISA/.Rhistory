library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Gráfico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
pisa %<>%
select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
# Valores duplicados: los eliminamos
pisa %<>% distinct(country, .keep_all = T)
# Valores nulos:
summarise_all(pisa, funs(sum(is.na(.))))
# Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
pisa <- na_mean(pisa)
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
# This is based on a “leave one out” cross-validation approach. The strategy is to remove one data point at a time, fit a smoother to the remaining data, and then fit of the smoother against the entire dataset. The goal is to pick the λj that minimizes the average error across all n validations.
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 10 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 10 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income) + health + s(edu) + s(hdi), data = pisa)
modelogam3 <- gam(overall ~ s(interest) + support + s(income) + health + s(edu) + s(hdi), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
#It seems like that addition of a linear interest, support and health components is much better than a GAM with them as a non-linear function because the p-value of 0.046 tell us that is significant.
summary(modelogam2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
pisa %<>%
select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
# Valores duplicados: los eliminamos
pisa %<>% distinct(country, .keep_all = T)
# Valores nulos:
summarise_all(pisa, funs(sum(is.na(.))))
# Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
pisa <- na_mean(pisa)
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
# This is based on a “leave one out” cross-validation approach. The strategy is to remove one data point at a time, fit a smoother to the remaining data, and then fit of the smoother against the entire dataset. The goal is to pick the λj that minimizes the average error across all n validations.
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 10 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 10 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income) + health + s(edu) + s(hdi), data = pisa)
modelogam3 <- gam(overall ~ s(interest) + support + s(income) + health + s(edu) + s(hdi), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
summary(modelogam2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'orange', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(3, 2))
plot(modelogam2, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
par(mfrow = c(2, 3))
plot(modelogam2, se = TRUE, col = 'green') #, residuals = TRUE, pch = 1, lwd = 2
modelogam1 <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
nrow(pisa[duplicated(pisa), ])
summarise_all(pisa, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
tail(pisa)
pisa %<>% select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
nrow(pisa[duplicated(pisa), ])
summarise_all(pisa, funs(sum(is.na(.))))
# This is based on a “leave one out” cross-validation approach. The strategy is to remove one data point at a time, fit a smoother to the remaining data, and then fit of the smoother against the entire dataset. The goal is to pick the λj that minimizes the average error across all n validations.
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Checking los modelos
gam.check(modelogam2)  #el que mejor explica el comportamiento de las variables
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
tail(pisa)
pisa %<>% select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
nrow(pisa[duplicated(pisa), ]) #cuentame los repetidos. No hay valores duplicados
summarise_all(pisa, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
pisa <- na_mean(pisa) # Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
# This is based on a “leave one out” cross-validation approach. The strategy is to remove one data point at a time, fit a smoother to the remaining data, and then fit of the smoother against the entire data set. The goal is to pick the lambda(j) that minimizes the average error across all n validations.
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 18 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 4 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income) + health + s(edu) + s(hdi), data = pisa)
modelogam3 <- gam(overall ~ s(interest) + support + s(income) + health + s(edu) + s(hdi), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
# Checking los modelos
gam.check(modelogam2)  #el que mejor explica el comportamiento de las variables
summary(modelogam2)
# Checking los modelos
gam.check(modelogam1)  #el que mejor explica el comportamiento de las variables
gam.check(modelogam2)  #el segundo modelo con las variables interest, support y health como lineales.
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
tail(pisa)
pisa %<>% select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
nrow(pisa[duplicated(pisa), ]) #cuentame los repetidos. No hay valores duplicados
summarise_all(pisa, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
pisa <- na_mean(pisa) # Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 18 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 4 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest) + s(support) + s(income) + s(health) + s(edu) + s(hdi), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income) + health + s(edu) + s(hdi), data = pisa)
modelogam3 <- gam(overall ~ s(interest) + support + s(income) + health + s(edu) + s(hdi), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
# Checking de los modelos
gam.check(modelogam1)  #el modelo con el primer gam
gam.check(modelogam2)  #el segundo modelo con las variables interest, support y health como lineales.
summary(modelogam2)
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
tail(pisa)
pisa %<>% select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
# Remove duplicate rows of the dataframe
pisa %<>% distinct(country,.keep_all= TRUE)
summarise_all(pisa, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
pisa <- na_mean(pisa) # Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 18 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 4 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest, k = 4.750171) + s(support, k = 2.001243) + s(income, k = 4.244952) + s(health, k = 2.002844) + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income) + health + s(edu) + s(hdi), data = pisa)
modelogam3 <- gam(overall ~ s(interest) + support + s(income) + health + s(edu) + s(hdi), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
modelogam2 <- gam(overall ~ interest + support + s(income, k = 4.244952) + health + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
modelogam3 <- gam(overall ~ s(interest, k = 4.750171) + support + s(income, k = 4.244952) + health + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
# Checking de los modelos
gam.check(modelogam1)  #el modelo con el primer gam
gam.check(modelogam2)  #el segundo modelo con las variables interest, support y health como lineales.
gam.check(modelogam3)  #tercer modelo gam dejando interest como no lineal
summary(modelogam2)
knitr::opts_chunk$set(echo = TRUE)
library(here) # Comentarios [//]:
library(tidyverse)
library(janitor) # Limpieza de nombres
library(skimr) # Summary pro
library(magrittr) # Pipe operators %<>%
library(corrplot) # Grafico de correlaciones
library(ggcorrplot)  # Correlaciones con ggplot
library(PerformanceAnalytics) # Otra correlación
library(imputeTS) # na_mean() reemplaza nulos por la media
library(broom) # Modelos en df
library(flextable) # Tablas formateadas
library(mgcv) # Estimaciones GAM
library(reshape2) # Melt DF
pisa <- read_csv("pisasci2006.csv")
head(pisa)
tail(pisa)
pisa %<>% select(Country, Overall, Interest, Support, Income, Health, Edu, HDI)
pisa %<>% clean_names()   # # clean_names() nos modifica aquellos nombres que tienen simbolos que estan reservados para calculo o como palabras reservadas del codigo.
colnames(pisa)
# Remove duplicate rows of the dataframe
pisa %<>% distinct(country,.keep_all= TRUE)
summarise_all(pisa, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
pisa <- na_mean(pisa) # Como existen muchos valores nulos los sustituimos por la media con la funcion na_mean() de la libreria imputeTS
skim(pisa)
chart.Correlation(pisa %>%
select_at(vars(-country)),
histogram = TRUE, pch = 19)  #sacamos las variables categoricas de nuestra matriz de correlaciones
attach(pisa)
fit_interest <- smooth.spline(x = interest, y = overall, cv = TRUE) # fit de la variable interest
fit_interest$df
fit_support <- smooth.spline(x = support, y = overall, cv = TRUE) # fit de la variable support
fit_support$df
fit_income <- smooth.spline(x = income, y = overall, cv = TRUE) # fit de la variable income
fit_income$df
fit_health <- smooth.spline(x = health, y = overall, cv = TRUE) # fit de la variable health
fit_health$df
fit_edu <- smooth.spline(x = edu, y = overall, cv = TRUE) # fit de la variable health
fit_edu$df
fit_hdi <- smooth.spline(x = hdi, y = overall, cv = TRUE) # fit de la variable hdi
fit_hdi$df
# Para nuestro ejemplo elegimos la variable hdi:
# Primero, generamos un smooth.spline con 18 grados de libertad (este número es al azar)
fitdf18_hdi <- smooth.spline(x = hdi, y = overall, df = 18)
# Ploteamos ambos modelos para comparar
plot(income, overall, col = 'black')
lines(fitdf18_hdi, col = 'red', lwd = 3)   # Plot del modelo con 18 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('18 DF', '8.60 DF'),   # Parametros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
fitdf4_hdi <- smooth.spline(x = hdi, y = overall, df = 4)
# Ploteamos ambos modelos para comparar
plot(hdi, overall, col = 'black')
lines(fitdf4_hdi, col = 'red', lwd = 3)   # Plot del modelo con 4 grados de libertad
lines(fit_hdi, col = 'blue', lwd = 3)            # Plot del modelo con los grados de libertad por CV
legend('topleft', legend = c('4 DF', '8.60 DF'),   # Parámetros de la leyenda
col = c('red', 'blue'), lty = 1, lwd = 3, cex = 1, bg = 'grey')
modelogam1 <- gam(overall ~ s(interest, k = 4.750171) + s(support, k = 2.001243) + s(income, k = 4.244952) + s(health, k = 2.002844) + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income, k = 4.244952) + health + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
modelogam3 <- gam(overall ~ s(interest, k = 4.750171) + support + s(income, k = 4.244952) + health + s(edu, k = 2.002385) + s(hdi, k = 8.603228), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
# Checking de los modelos
gam.check(modelogam1)  #el modelo con el primer gam
gam.check(modelogam2)  #el segundo modelo con las variables interest, support y health como lineales.
gam.check(modelogam3)  #tercer modelo gam dejando interest como no lineal
summary(modelogam2)
modelogam1 <- gam(overall ~ s(interest, k = 4.75) + s(support, k = 2.00) + s(income, k = 4.24) + s(health, k = 2.00) + s(edu, k = 2.00) + s(hdi, k = 8.60), data = pisa)
par(mfrow = c(2, 3))
plot(modelogam1, se = TRUE, col = 'green', residuals = TRUE, pch = 1, lwd = 2)
modelogam2 <- gam(overall ~ interest + support + s(income, k = 4.24) + health + s(edu, k = 2.00) + s(hdi, k = 8.60), data = pisa)
modelogam3 <- gam(overall ~ s(interest, k = 4.75) + support + s(income, k = 4.24) + health + s(edu, k = 2.00) + s(hdi, k = 8.60), data = pisa)
anova(modelogam1, modelogam2, modelogam3, test = 'F')
# Checking de los modelos
gam.check(modelogam1)  #el modelo con el primer gam
gam.check(modelogam2)  #el segundo modelo con las variables interest, support y health como lineales.
gam.check(modelogam3)  #tercer modelo gam dejando interest como no lineal
summary(modelogam2)
